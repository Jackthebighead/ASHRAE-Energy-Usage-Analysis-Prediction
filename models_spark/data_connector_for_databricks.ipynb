{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "06ba8ff9-d39d-4def-ab1f-5b04bb01de70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.139.64.4:44155\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://10.139.64.4:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.139.64.4:44155\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.139.64.4:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "removedWidgets": [],
       "textData": "<div class=\"ansiout\">Out[13]: </div>",
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "30bed2ad-ae46-45db-93d5-765f6a2efc5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import bson\n",
    "from bson import ObjectId\n",
    "from bson import json_util as jsonb\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import dns\n",
    "import numpy as np\n",
    "#import dnspython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1a39c126-cf6b-4fbe-ae6d-5c54d92a9b8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Data Loaded\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Data Loaded\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weather_train_pd = pd.read_csv(\"/dbfs/FileStore/tables/weather_train.csv\", header='infer')\n",
    "weather_test_pd = pd.read_csv(\"/dbfs/FileStore/tables/weather_test.csv\", header='infer')\n",
    "train_pd = pd.read_csv(\"/dbfs/FileStore/tables/train.csv\", header='infer')\n",
    "test_pd = pd.read_csv(\"/dbfs/FileStore/tables/test.csv\", header='infer')\n",
    "building_pd = pd.read_csv(\"/dbfs/FileStore/tables/building_metadata.csv\", header='infer')\n",
    "print('Data Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cf17b5d8-836a-4c2b-8af1-df4c07864648",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">the size of train dataset: (20216100, 4)\n",
       "the size of test dataset: (41697600, 4)\n",
       "the size of weather_train dataset: (139773, 9)\n",
       "the size of weather_test dataset: (277243, 9)\n",
       "the size of building_metadata dataset: (1449, 6)\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">the size of train dataset: (20216100, 4)\nthe size of test dataset: (41697600, 4)\nthe size of weather_train dataset: (139773, 9)\nthe size of weather_test dataset: (277243, 9)\nthe size of building_metadata dataset: (1449, 6)\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('the size of train dataset:', train_pd.shape)\n",
    "print('the size of test dataset:', test_pd.shape)\n",
    "print('the size of weather_train dataset:', weather_train_pd.shape)\n",
    "print('the size of weather_test dataset:', weather_test_pd.shape)\n",
    "print('the size of building_metadata dataset:', building_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "611f9134-4931-4d97-9a4d-256e4c1fbb96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Core class in this notebook\n",
    "class mongoDB():\n",
    "    \n",
    "    \"\"\"\n",
    "    Class Description:\n",
    "    - Designed to run in Azure Databricks\n",
    "    - Original version (run locally) in `data_connector.ipynb`\n",
    "    - Serve as the Data Connector layer in the project. \n",
    "    - raw_data->database->spark_data\n",
    "        \n",
    "    Initialization:\n",
    "      - host_address\n",
    "      - port_number\n",
    "      - connect the Mongo client\n",
    "      \n",
    "    Functions: \n",
    "      - Create a MongoDB service for the user\n",
    "      - Write raw data (pd.dataframe)/huge raw data into mongodb collections\n",
    "      - Load mongodb collections into Spark.DataFrame\n",
    "      - Drop existing collections\n",
    "      - Count the number of rows in a collection\n",
    "      - Close MongoDB connection\n",
    "    \n",
    "    Notices:\n",
    "      - Use close_connection after finishing using mongo service (for the best)\n",
    "    \n",
    "    \"\"\"  \n",
    "    \n",
    "    def __init__(self, username='YanzheYUAN', password='YanzheYUAN', cluster_name='cluster0', database_name='ashrae_db'):\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.cluster_name = cluster_name\n",
    "        self.database_name = database_name\n",
    "        # Create a MongoClient to the running mongod instance\n",
    "        self.mongo_client = MongoClient('mongodb+srv://'+username+':'+password+'@'+cluster_name+'.3khuz.mongodb.net/'+database_name+'?retryWrites=true&w=majority') \n",
    "        \n",
    "        '''\n",
    "        An alternative way to link to mongodb\n",
    "        #from pyspark.sql import SparkSession\n",
    "        #my_spark = SparkSession \\\n",
    "        #    .builder \\\n",
    "        #    .appName(\"Databricks Shell\") \\\n",
    "        #    .getOrCreate()\n",
    "        #df = my_spark.read.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "        #  .option(\"uri\", 'mongodb+srv://YanzheYUAN:YanzheYUAN@cluster0.3khuz.mongodb.net/sample_airbnb.listingsAndReviews?retryWrites=true&w=majority') \\\n",
    "        #  .load()\n",
    "        '''\n",
    "    \n",
    "    def data_to_db(self, database_name='ashrae_db', collection_name='collection_test', raw_data=pd.DataFrame(np.arange(100).reshape(25,4), columns=list('wxyz'))):\n",
    "        '''\n",
    "        Write raw data (pd.dataframe form) into mongodb database (as a collection)\n",
    "        '''\n",
    "        \n",
    "        client = self.mongo_client\n",
    "        \n",
    "        # Create a database inside this client\n",
    "        db = client[database_name]\n",
    "\n",
    "        # Create a collection inside this database.\n",
    "        # A collection is a group of documents stored in MongoDB, and can be thought of as roughly the equivalent of a table in a relational database\n",
    "        collection = db[collection_name]\n",
    "\n",
    "        # Data in MongoDB is represented (and stored) using JSON-style documents. In PyMongo we use dictionaries to represent documents.\n",
    "        # data = your_df.to_dict(orient='record') / mycol.insert_many(data) may be useful as well.\n",
    "        print('----------------------------------------------')\n",
    "        print('Start Inserting......')\n",
    "        collection.insert_many(json.loads(raw_data.T.to_json()).values())\n",
    "    \n",
    "        # print related information\n",
    "        # print()\n",
    "        print('- Data inserted to Database:', database_name, 'Collection:', collection_name)\n",
    "        # print('There are other collections:', db.list_collection_names(), 'And other databases:', client.list_database_names())\n",
    "        print('- The number of rows in', collection_name, 'is', collection.count_documents({}))\n",
    "        print('- Fetch the first row in the collection', jsonb.dumps(list(collection.find_one())))\n",
    "        print('Data Loaded')\n",
    "    \n",
    "        '''\n",
    "        If there are redundant info in the collection, use the following commands and simply rerun this function:\n",
    "          client = MongoClient()\n",
    "          db = client['database_test_1']\n",
    "          collection = db['collection_test_1']\n",
    "          collection.drop()\n",
    "          client.close()\n",
    "        Alternatively, use the following to remove single document\n",
    "          # collection.remove( {'_id':id_num}) \n",
    "          db.test.delete_many({'x': 1})\n",
    "        Use the following to find all documents in oone collection:\n",
    "          list(collection.find())\n",
    "        '''\n",
    "\n",
    "    def huge_data_to_db(self, database_name='ashrae_db', collection_name='collection_test', data=pd.DataFrame(np.arange(100).reshape(25,4), columns=list('wxyz')),split_num=10):\n",
    "        '''\n",
    "        Split big data into pieces and feed them into mongoDB piece by piece in order to show the process\n",
    "        '''\n",
    "        def split_df(data=pd.DataFrame(np.arange(100).reshape(25,4), columns=list('wxyz')), split_num=10):\n",
    "            '''\n",
    "            Split raw data (pd.DataFrame form) into different pieces so that it is available to load into mongoDB\n",
    "            '''\n",
    "            df_length = data.shape[0]\n",
    "            result = []\n",
    "            start = 0\n",
    "            end = 0\n",
    "            for i in range(1,split_num+1):\n",
    "                print(i)\n",
    "                if i == split_num:\n",
    "                    end = df_length\n",
    "                else:\n",
    "                    end=i*int(df_length/split_num)\n",
    "                print('start',start)\n",
    "                print('end',end)\n",
    "                result.append(data[start:end])\n",
    "                start=end\n",
    "            return result\n",
    "        \n",
    "        self.get_row_num(database_name, collection_name)\n",
    "        print('--------------Start At:', datetime.datetime.now(),'----------------')\n",
    "        \n",
    "        df_splited = split_df(data,split_num)\n",
    "        for i,item in enumerate(df_splited):\n",
    "            self.data_to_db(database_name, collection_name, item)\n",
    "            print(\"--------------Data split\",i+1,\"has been loaded----------------\")\n",
    "        \n",
    "        print('--------------Finish At:', datetime.datetime.now(),'----------------')\n",
    "        self.get_row_num(database_name, collection_name)\n",
    "        \n",
    "    def db_to_data(self, database_name='ashrae_db', collection_name='collection_test', query={}, id_exist=False):\n",
    "        '''\n",
    "        Load collections/data from collections to Spark_DataFrame\n",
    "        '''\n",
    "        collection = self.mongo_client[database_name][collection_name]\n",
    "        cursor = collection.find(query)\n",
    "        df = pd.DataFrame(list(cursor))\n",
    "        if bool(1-id_exist):\n",
    "            del df['_id']\n",
    "        print('Data Loaded')\n",
    "        return df\n",
    "    \n",
    "    def drop_collection(self, database_name='ashrae_db', collection_name='collection_test'):\n",
    "        '''\n",
    "        Drop a collection(table) in a database, all specified.\n",
    "        '''\n",
    "        collection = self.mongo_client[database_name][collection_name]\n",
    "        collection.drop()\n",
    "        print('Collection Dropped')\n",
    "    \n",
    "    def get_row_num(self, database_name='ashrae_db', collection_name='collection_test'):\n",
    "        '''\n",
    "        Get the number of rows in the specified collection\n",
    "        '''\n",
    "        collection = self.mongo_client[database_name][collection_name]\n",
    "        print('There are', collection.count_documents({}),'rows of data in the collection.')\n",
    "\n",
    "    def close_connection(self):\n",
    "        self.mongo_client.close()\n",
    "        print('Client Closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f19080c1-5b8a-4619-965d-dd121cba7a39",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">----------------------------------------------\n",
       "Start Inserting......\n",
       "- Data inserted to Database: ashrae_db Collection: weather_train\n",
       "- The number of rows in weather_train is 139773\n",
       "- Fetch the first row in the collection [&#34;_id&#34;, &#34;site_id&#34;, &#34;timestamp&#34;, &#34;air_temperature&#34;, &#34;cloud_coverage&#34;, &#34;dew_temperature&#34;, &#34;precip_depth_1_hr&#34;, &#34;sea_level_pressure&#34;, &#34;wind_direction&#34;, &#34;wind_speed&#34;]\n",
       "Data Loaded\n",
       "----------------------------------------------\n",
       "Start Inserting......\n",
       "- Data inserted to Database: ashrae_db Collection: weather_test\n",
       "- The number of rows in weather_test is 277243\n",
       "- Fetch the first row in the collection [&#34;_id&#34;, &#34;site_id&#34;, &#34;timestamp&#34;, &#34;air_temperature&#34;, &#34;cloud_coverage&#34;, &#34;dew_temperature&#34;, &#34;precip_depth_1_hr&#34;, &#34;sea_level_pressure&#34;, &#34;wind_direction&#34;, &#34;wind_speed&#34;]\n",
       "Data Loaded\n",
       "----------------------------------------------\n",
       "Start Inserting......\n",
       "- Data inserted to Database: ashrae_db Collection: building_metadata\n",
       "- The number of rows in building_metadata is 1449\n",
       "- Fetch the first row in the collection [&#34;_id&#34;, &#34;site_id&#34;, &#34;building_id&#34;, &#34;primary_use&#34;, &#34;square_feet&#34;, &#34;year_built&#34;, &#34;floor_count&#34;]\n",
       "Data Loaded\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">----------------------------------------------\nStart Inserting......\n- Data inserted to Database: ashrae_db Collection: weather_train\n- The number of rows in weather_train is 139773\n- Fetch the first row in the collection [&#34;_id&#34;, &#34;site_id&#34;, &#34;timestamp&#34;, &#34;air_temperature&#34;, &#34;cloud_coverage&#34;, &#34;dew_temperature&#34;, &#34;precip_depth_1_hr&#34;, &#34;sea_level_pressure&#34;, &#34;wind_direction&#34;, &#34;wind_speed&#34;]\nData Loaded\n----------------------------------------------\nStart Inserting......\n- Data inserted to Database: ashrae_db Collection: weather_test\n- The number of rows in weather_test is 277243\n- Fetch the first row in the collection [&#34;_id&#34;, &#34;site_id&#34;, &#34;timestamp&#34;, &#34;air_temperature&#34;, &#34;cloud_coverage&#34;, &#34;dew_temperature&#34;, &#34;precip_depth_1_hr&#34;, &#34;sea_level_pressure&#34;, &#34;wind_direction&#34;, &#34;wind_speed&#34;]\nData Loaded\n----------------------------------------------\nStart Inserting......\n- Data inserted to Database: ashrae_db Collection: building_metadata\n- The number of rows in building_metadata is 1449\n- Fetch the first row in the collection [&#34;_id&#34;, &#34;site_id&#34;, &#34;building_id&#34;, &#34;primary_use&#34;, &#34;square_feet&#34;, &#34;year_built&#34;, &#34;floor_count&#34;]\nData Loaded\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an instance of class mongoDB and load data to mongodb database called ashrae_db\n",
    "instance = mongoDB()\n",
    "instance.data_to_db('ashrae_db','weather_train',weather_train_pd)\n",
    "instance.data_to_db('ashrae_db','weather_test',weather_test_pd)\n",
    "instance.data_to_db('ashrae_db','building_metadata',building_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b069ef73-b336-41be-b233-7ab45766f9da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">There are 139773 rows of data in the collection.\n",
       "There are 277243 rows of data in the collection.\n",
       "There are 1449 rows of data in the collection.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">There are 139773 rows of data in the collection.\nThere are 277243 rows of data in the collection.\nThere are 1449 rows of data in the collection.\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if loaded\n",
    "instance.get_row_num('ashrae_db','weather_train')\n",
    "instance.get_row_num('ashrae_db','weather_test')\n",
    "instance.get_row_num('ashrae_db','building_metadata')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cfc02ce5-e5b4-4040-bc88-4efc56662a4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load train data (relatively large data)\n",
    "\n",
    "# instance.huge_data_to_db('ashrae_db','train',train_pd,100)\n",
    "\n",
    "# The data size exceeds the limit of mongoDB Atlas(free trial), so we upload the train.csv and test.csv, while building_csv, weather_train.csv and weather_test.csv are stored in the mongoDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ab9993be-4923-49ec-bbe4-783cfc3948be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load train data (relatively large data)\n",
    "\n",
    "#instance.huge_data_to_db('ashrae_db','test',test_pd,200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7f550a2c-6a5b-4399-9f13-5f7437b04ac7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import pymongo\n",
    "#client = pymongo.MongoClient(\"mongodb+srv://YanzheYUAN:YanzheYUAN@cluster0.3khuz.mongodb.net/sample_weatherdata?retryWrites=true&w=majority\")\n",
    "#db = client.sample_weatherdata\n",
    "#collection = db.data\n",
    "#collection.find_one()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1db8974a-e035-40dd-8128-72d0c9ac4d79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "57c74f0b-44e5-4b95-a757-335170f7dfbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "43842184-2472-4aad-9b5b-2c76d5df7a36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "data_connector_for_databricks",
   "notebookOrigID": 2633416938972242,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
